# Deep-Fake API

This project is a FastAPI backend that runs deep-fake detection on videos.  
You send a short video â†’ it extracts frames â†’ detects faces â†’ runs them through a deep learning model (ResNeXt + BiLSTM) â†’ and returns if the video is FAKE or REAL with a confidence score.

âš ï¸ **Note:** The model weights (`checkpoint.pth`) are **not in this repo**.  
I keep them in my Drive:  
`IMAP > publication > amine > checkpoint`  
You need to download the checkpoint before using the API.

---

## ðŸ”§ Tech Stack

- **FastAPI + Uvicorn** â†’ REST API
- **PyTorch** â†’ deep learning runtime
- **OpenCV / dlib** â†’ video decoding, frame extraction, face detection
- **Model** â†’ ResNeXt (for spatial features) + BiLSTM (for temporal sequence consistency)

---

## ðŸ“‚ Repo structure

- `apiForAppNewOne.py` â†’ main FastAPI app  
- `deepfake_model.py`, `model_definition.py` â†’ model loader + forward pass  
- `video_utils.py` â†’ video preprocessing, face detection, normalization  
- `usage_example.py` â†’ client example to call the API  
- `requirements.txt` â†’ dependencies  
- `benchmark_*` + `apiBenchmark.py` â†’ quick perf tests (latency/throughput)  
- `videos/` and `SHORT_VIDEO_HD/` â†’ demo input videos  

---

## ðŸš€ How to run

### 1) Setup
```bash
python -m venv .venv
source .venv/bin/activate        # (Windows: .venv\Scripts\activate)
pip install -r requirements.txt
